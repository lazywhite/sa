Hadoop组件 
	1. Hadoop Common: hadoop基础库
	2. HDFS: 分布式文件系统
	3. Hadoop YARN: mapreduce框架
	4. Hadoop MapReduce: mapreduce实现

Mapreduce
	job tracker(单点master)
	task tracker(最好运行在datanode, 可以有多个)
	
HDFS
	NameNode
    Secondary NameNode
	DataNode
	File
		Block: 默认大小为64Mkko
		Replication: 每个block的备份数ko

NameNode高可用
    1. 启动多个NameNode, 只有一个处于Active状态
    2. 通过相互独立的"journal node"进程进行通信, 同步Active上namespace的更改到本地
    3. DataNode需要同时向多个NameNode会报
    4. 共享edits log, 达到快速failover的目的, 共享的方式有以下两种
        Quorum Journal Manager (QJM)
        NFS
    5. 需要借助zookeeper进行选举和切换
	
Hadoop Streaming
	用任意类型的脚本或语言创建hadoop jobs
    自定义mapper.py, reducer.py
    运行 #hadoop jar contrib/streaming/hadoop-streaming-1.2.1.jar -input myinput -output myoutput -mapper /home/expert/hadoop-1.2.1/mapper.py -reducer /home/expert/hadoop-1.2.1/reducer.py


Job执行流程
	1.用户提交job给jobtracker
	2.jobtracker查询namenode, 获得数据的存放位置
	3.jobtracker筛选出离数据近或就在数据节点的taskTracker
	4.jobTracker分配任务给TaskTracker
	5.TaskTracker的执行状态被监控, 必须向jobtracker发送心跳信息, 如果不发送, task被重新调度给其他TaskTracker

Dashboard
	http://localhost:50070/

job执行管理
	http://localhost:8088/
	
更改默认块大小
  	hadoop fs -D dfs.blocksize=268435456 -copyFromLocal /hirw-starterkit/hdfs/commands/dwp-payments-april10.csv blksize/dwp-payments-april10_256MB.csv 

Hadoop涉及的端口
    9000    fs.defaultFS，如：hdfs://172.25.40.171:9000
    9001    dfs.namenode.rpc-address，DataNode会连接这个端口
    50070   dfs.namenode.http-address
    50470   dfs.namenode.https-address
    50100   dfs.namenode.backup.address
    50105   dfs.namenode.backup.http-address
    50090   dfs.namenode.secondary.http-address，如：172.25.39.166:50090
    50091   dfs.namenode.secondary.https-address，如：172.25.39.166:50091
    50020   dfs.datanode.ipc.address
    50075   dfs.datanode.http.address
    50475   dfs.datanode.https.address
    50010   dfs.datanode.address，DataNode的数据传输端口
    8480    dfs.journalnode.rpc-address
    8481    dfs.journalnode.https-address
    8032    yarn.resourcemanager.address
    8088    yarn.resourcemanager.webapp.address，YARN的http端口
    8090    yarn.resourcemanager.webapp.https.address
    8030    yarn.resourcemanager.scheduler.address
    8031    yarn.resourcemanager.resource-tracker.address
    8033    yarn.resourcemanager.admin.address
    8042    yarn.nodemanager.webapp.address
    8040    yarn.nodemanager.localizer.address
    8188    yarn.timeline-service.webapp.address
    10020   mapreduce.jobhistory.address
    19888   mapreduce.jobhistory.webapp.address
    2888    ZooKeeper，如果是Leader，用来监听Follower的连接
    3888    ZooKeeper，用于Leader选举
    2181    ZooKeeper，用来监听客户端的连接
    60010   hbase.master.info.port，HMaster的http端口
    60000   hbase.master.port，HMaster的RPC端口
    60030   hbase.regionserver.info.port，HRegionServer的http端口
    60020   hbase.regionserver.port，HRegionServer的RPC端口
    8080    hbase.rest.port，HBase REST server的端口
    10000   hive.server2.thrift.port
    9083    hive.metastore.uris
