# 一. yarn queue

## (1)修改queue配置
1. 指定调度器yarn.resourcemanager.scheduler.class
2. 在对应调度器配置文件中配置queue conf/capacity-scheduler.xml
3. yarn rmadmin -refreshQueues

## (2)查看queue
hadoop queue -list
hadoop queue -info <queue_name> 
hadoop queue -info <queue_name>  -showJobs

## (3)指定queue
hadoop
    hadoop jar app.jar -D mapreduce.job.queuename=root.mr -D mapreduce.job.priority=HIGH


Hive
    设置执行引擎
        set hive.execution.engine=mr;  
        set hive.execution.engine=spark;  
        set hive.execution.engine=tez;  
    设置队列
        SET mapreduce.job.queuename=root.up;
        SET mapreduce.job.priority=HIGH;
        set tez.queue.name=cmbi;
   
Pig
   SET mapreduce.job.queuename root.up;
   SET mapreduce.job.priority HIGH;

spark
    spark-submit --conf spark.yarn.queue=default # 自动匹配
    spark-submit --conf spark.yarn.queue=root.queue1.child1 # 绝对路径
    spark-submit --conf spark.yarn.queue=child1  # 自队列也能自动匹配

# 二. Job
hadoop job -list [all]
hadoop job -kill <job_id>

yarn logs -applicationId <app ID>   > a.log  # 每个log对应一个hdfs路径， 里面存的数据不是txt， 必须用输出重定向  


yarn application -list  
