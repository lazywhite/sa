OS Linux:
	
	PC Arch: CPU, Memory, I/O
	OS: 进程调度器、内存管理、驱动程序


中断上半部，下半部

TLB：


buddy allocator: 避免内存外碎片
slab allocator: 避免内存内碎片



程序概要分析是收集有关程序执行时其行为的过程。您可以分析一个程序以便决定可以优化程序的哪个部分以便提高该程序的总体速度，减少其内存使用等等。程序分析工具可以帮助您简化这个过程。

红帽企业版 Linux 6 支持三个分析工具：SystemTap、OProfile 和 Valgrind。


SystemTap

SystemTap 是一个跟踪和探测工具，可让用户监控并分析操作系统活动（特别是内核活动）的细节。它提供类似 netstat、top、ps 和 iostat 等工具的输出结果，但包含为所收集信息的额外过滤和分析选项。
SystemTap 提供深入准确的系统活动和程序行为分析，以便您可以准确包我系统和程序瓶颈。
Eclipse 的功能函数图插件使用 SystemTap 作为后端，可让其完整监控程序状态，其中包括功能调用、返回、次数以及用户空间变量，并以直观形式显示以便优化。
有关 SystemTap 的详情请参考《SystemTap 初学者指南》，地址为 http://access.redhat.com/site/documentation/Red_Hat_Enterprise_Linux/。

OProfile

OProfile（oprofile）是一个系统范围的性能监控工具。它使用处理器专用性能监控硬件搜索有关内核和系统可执行程序的信息，比如何时参考内存，L2 缓存要求数，以及收到的硬件中断数。它还可以用来决定处理器用量，以及使用最多的应用程序和服务。
Oprofile 还可以通过 Eclipse Oprofile 插件与 Eclipse 一同使用。这个插件可以让用户轻松确定其代码中最耗时的部分，并在执行 OProfile 的所有命令行功能时获得最丰富的直观结果。

但用户应该注意到 OProfile 的几个限制：
性能监控示例可能不准确因为该处理器可能没有按顺序执行指令，可能是根据最接近的指令执行，而不是触发中断的指令。
因为 OProfile 是系统范围内的程序，且会多次启动和停止，多次运行的示例允许有累积。就是说您需要清除以前程序运行产生的示例数据。
它主要是识别有 CPU 限制的问题进程，因此无法识别等待为其他事件锁定而处于睡眠状态的进程。

有关使用 OProfile 的详情请参考 《部署指南》，地址为 http://access.redhat.com/site/documentation/Red_Hat_Enterprise_Linux/；或者 /usr/share/doc/oprofile-<version> 中的 oprofile 文档。


Valgrind

Valgrind 提供大量探测和分析工具以便帮助您改进性能并修正您的程序。这些工具可以探测与内存和线程有关的错误，以及堆、栈和阵列过度运行，以便您在程序代码中轻松定位并修改错误。他们还可以分析缓存，堆，以及分支预测以便识别增加程序速度，减少程序内存使用的因素。
Valgrind 通过在综合CPU 运行分析您的程序，并检测其执行的程序代码。然后它会输出“说明”明确为用户指定的文件描述符、文件或者网络插槽鉴别出执行程序所涉及的每个进程。检测等级根据 Valgrind 工具的使用及设置而有所不同，但重要的是注意执行检测的代码的时间比一般执行代码要长 4-50 倍。
Valgrind 可以在您的程序中原封不动地使用，不需要重新编译。但因为 Valgrind 使用调试信息锁定代码中的问题，如果您的程序以及支持库无法使用启用的调试信息编译，则强烈建议您将重新编译包含在这个信息中。

从红帽企业版 Linux 6.4 开始 Valgrind 整合了 gdb (GNU Project Debugger) 以改进调试效率。
有关 Valgrind 的详情请参考《开发者指南》，地址为 http://access.redhat.com/site/documentation/Red_Hat_Enterprise_Linux/。或者在安装 valgrind 软件包后查看 man valgrind 命令。附带的文档也可在此找到：
/usr/share/doc/valgrind-<version>/valgrind_manual.pdf
/usr/share/doc/valgrind-<version>/html/index.html


Perf
perf 工具提供大量有用的性能计数器，可让用户评估其系统中其他程序的影响：

perf stat
这个命令常见性能事件的总体统计，其中包括执行的质量以及消耗的时钟周期。您可以使用选项标签收集事件中默认测量事件以外的统计数据。从红帽企业版 Linux 6.4 开始，还可以使用 perf stat 过滤根据一个或者多个指定的控制组（cgroup）指定的监控。有关详情请查看 man page：man perf-stat。

perf record
这个命令将性能数据记录到文件中，以后可以使用 perf report 进行分析。有关详情请查看 man page：man perf-record。

perf report
这个命令从文件中读取性能数据并分析记录的数据。有关详情请查看 man page：man perf-report。

perf list
这个命令列出具体机器中的可用事件。这些时间随性能监控硬件以及系统软件配置而有所不同。有关详情请查看 man page：man perf-list

perf top
这个命令与 top 工具的功能类似。它可以实时生成并显示性能计数器分析。有关详情请查看 man page：man perf-top。
















内存调优：

page cache: 缓存的文件数据
buffers: 缓存文件的元数据(inode+denty)，

1 
2
3


swappiness: 0-100


OOM: Out Of Memory

/proc/PID/oom_score
/proc/PID/oom_adj

echo f > /proc/sysrq-trigger

vm/panic_


软限制：
硬限制：

/etc/security/limits.conf








page-out === The system's free memory is less than a threhsold "lotsfree" and vhand daemon used "LFU" algorithm to move some unused / least used pages to the swap area.

page-in === One process which is running requested for a page that is not in the current memory (page-fault), vhand daemon is bringing it's pages to memory.

swap-out === System is thrashing and swapper daemon has de-activated a process and it's memory pages are moved into the swap area.

swap-in === A deactivated process is back to work and it's pages are being brought into the memory.






Page in - Page outs - They are similar in function to any other operating system. When a particular page is requested by the main memory, but it is not present in the main memory; a page fault occurs...and this page is "paged in" to the main memory. Similarlly pages that have been inactive for a while are "paged out" to page data sets on the auxillary memory. 

Swap in - Swap out - This is very specific to MVS. MVS sometimes pages out all the pages of a particular address space which is no longer active to accomdate higher priority address spaces. This collective page out of all the pages of a particular address space is called swap out. 



swappiness: 0-100
	
overcommit_memory
	0
	1
	2	
overcommit_ratio


IPC: 

msgmax
msgmnb
msgmni

shmall：
shmmax：
shmmni：



dirty_ratio
dirty_backgroup_ration
dirty_expirt_centisecs
dirty_writeback_centisecs


drop_caches: 
	1, page cache
	2, inode and dentry
	3


/etc/security/limit.conf

<domain>	<type>  <item>   <value>
tom			soft	nofile	10240


ulimit -n






Queue length
/sys/block/<dev>/queue/nr_requests

Max read-ahead
/sys/block/<dev>/queue/read_ahead_kb



IO压力测试工具：
	aio-stress
	iozone
	fio

	磁盘活动状况分析：blktrace, blkparse

	gnuplot

IO优化：
	选择io scheduler
	配置scheduler的参数

	使用工具分析调整后的结果：

写在/etc/rc.d/rc.local文件中。






文件系统：
inode: 块指针
	权限，mode
	属主
	属组
	大小
	atime
	mtime
	ctime
	扩展属性：lsattr, chattr

atime: 




strace: 追踪系统调用


dumpe2fs 查看块组内的碎片

filefrag 查看文件是否被碎片化存储





FS块大小：合适块大小，在创建文件系统时确定；
使用外部日志，但管理麻烦；将日志放在其它磁盘上；



ext4文件的优化思路：
	nobarrier
	noatime, nodiratime
	改变块设备物理级别预读大小，而后改变调度器相关的参数，使用更大的预计功能；仅适用于大量顺序读写的场景；
	选择合适的块大小；

xfs文件系统：
	默认已经为较好的设定；
	nobarrier和noatime依然可用；

mysql数据文件在xfs文件系统上的性能表现要优于ext4；


aio-stress, iozone, fio, dd, bonie++
blktrace, blkparse



iozone, /opt/

io调度器：每磁盘
	cfq
	deadline
	anticipatory
	noop

echo "io_scheduler" > /sys/block/<dev>/queue/scheduler

写入/etc/rc.d/rc.local文件中以实现持久有效；


sysfs: 
	/sys/block/<dev>/queue/iosched/
		有许多参数文件


文件系统的：

noatime, nobarrier

ext4, xfs, ext3

data={journal|ordered|writeback}




sar -n SOCK
 totsck: 系统持有的socket个数；
 tcpsck: 当前正在使用的tcp socket的个数；
 ip-frag: 当前正在使用ip分片的个数；
 tcp-tw: 处于tw状态的tcp套接字的个数；

lsof -i 172.16.100.15:80
lsof -i :80

lsof -l
lsof -u USERNAME


netstat -tun | awk '/^tcp/{state[$NF]++}END{for (S in state) print state[S],S}' | sort -rn

dstat



网络子系统优化：

dstat命令跟网络相关的选项：
       --raw  enable raw stats (raw sockets)

       --socket
              enable socket stats (total, tcp, udp, raw, ip-fragments)

       --tcp  enable tcp stats (listen, established, syn, time_wait, close)

       --udp  enable udp stats (listen, active)

       --unix enable unix stats (datagram, stream, listen, active)

       -n, --net   enable network stats (receive, send)

       -N eth1,total   include eth1 and total

       --net-packets show the number of packets received and transmitted

其它常用的选项：

       --top-bio
              show most expensive block I/O process

       --top-cpu
              show most expensive CPU process

       --top-cputime
              show process using the most CPU time (in ms)

       --top-cputime-avg
              show process with the highest average timeslice (in ms)

       --top-io
              show most expensive I/O process

       --top-latency
              show process with highest total latency (in ms)

       --top-latency-avg
              show process with the highest average latency (in ms)

       --top-mem
              show process using the most memory

       --top-oom
              show process that will be killed by OOM the first






网络优化参数：

net.ipv4.tcp_max_tw_buckets
timewait的数量，默认为8192；

net.ipv4.ip_local_port_range = 1024 65000
允许系统打开的端口范围，前而为下限，后面的数字为上限；默认为“32768	61000”；
注意：此可用范围决定了最后timewait状态的连接的数量；下面的两项可有效降低tw状态连接的数量；

net.ipv4.tcp_tw_recycle = {0|1}
是否启用timewait快速回收；注意：开启此功能在NAT环境下可能会出现严重的问题：因为TCP有一种行为，它可以缓存每个连接最新的时间戳，后续请求中如果时间戳小于缓存中的时间戳，即被视为无效并丢弃相应的请求报文；Linux是否启用这种行为取决于tcp_timestamp和tcp_tw_recycle，而前一个参数默认是启用的，所以启用后面的参数就会激活此功能；
因此，如果是NAT环境，安全起见，应该禁用tcp_tw_recycle。另一种解决方案：把tcp_timestamps设置为0，tcp_tw_recycle设置为1并不会如想象中奏效，因为一旦关闭了tcp_timestamps，那么即便打开了tcp_tw_recycle，后面的参数也没有效果。此时降低net.ipv4.tcp_max_tw_buckets的值就可以显著降低tw连接的数量了。


net.ipv4.tcp_tw_reuse = {0|1}
是否开启tw重用，即是否允许将TIME-WAIT sockets 用于新的TCP连接；

net.ipv4.tcp_syncookies = {0|1}
是否开启SYN Cookies，即当SYN等待队列溢出时，是否启用cookies功能；

net.ipv4.tcp_timestamps = 0
tcp报文时间戳，关闭时可以避免序列号的卷绕，如上所述；


net.ipv4.tcp_max_syn_backlog = 262144
保存的那些尚未收到客户端确认信息的连接请求的最大值；默认为128，可增大此值；


net.ipv4.tcp_synack_retries = #
为了打开对端的连接，内核需要发送一个SYN并附带一个回应前面一个SYN的ACK，这也即所谓的三次握手中的第二次；这个设置决定了内核放弃连接之前发送SYN+ACK 包的数量；繁忙的服务器上建议设置为0或者1；

net.ipv4.tcp_syn_retries = #
在内核放弃建立连接之前发送SYN包的数量；繁忙的服务器上建议设置为0或者1；

net.ipv4.tcp_max_orphans = 262144
系统中最多有多少个TCP套接字不被关联到任何一个用户文件句柄上；如果超过这个数字，孤儿连接将即刻被复位并打印出警告信息；
这个限制仅仅是为了防止简单的DoS 攻击，不能过分依靠它或者人为地减小这个值，如果需要修改，在确保有足够内存可用的前提下，应该增大此值；


net.ipv4.tcp_fin_timeout = 5
如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间；缺省值是60秒。
然而，对端可能会出错或意外宕机并永远不关闭连接。即使你的机器是一个轻载的WEB 服务器，也有因为大量的死套接字而内存溢出的风险，FIN-WAIT-2 的危险性比FIN-WAIT-1要小，因为每个连接最多只能消耗1.5K内存，但是它们的生存期长些；

net.ipv4.tcp_keepalive_time = 30
当keepalive起用的时候，TCP发送keepalive消息的频度，默认是是2小时；

net.core.rmem_max=8388608 
定义内核用于所有类型的连接的最大接收缓冲大小；

net.core.rmem_default=65536 
定义内核用于所有类型的连接的默认接收缓冲大小；

net.core.wmem_max=8388608
定义内核用于所有类型的连接的最大发送缓冲大小；

net.core.wmem_default=65536 
定义内核用于所有类型的连接的默认发送缓冲大小；

net.ipv4.tcp_mem='8388608 8388608 8388608' 
定义TCP协议栈使用的内存空间；分别为最小值，默认值和最大值；

net.ipv4.tcp_rmem='4096 87380 8388608'
定义TCP协议栈用于接收缓冲的内存空间；第一个值为最小值，即便当前主机内存空间吃紧，也得保证tcp协议栈至少有此大小的空间可用；第二个值为默认值，它会覆盖net.core.rmem_default中为所有协议定义的接收缓冲的大小；第三值为最大值，即能用于tcp接收缓冲的最大内存空间；

net.ipv4.tcp_wmem='4096 65536 8388608'  
定义TCP协议栈用于发送缓冲的内存空间；




lsof -n：不反解IP至HOSTNAME
lsof -i：用以显示符合条件的进程情况
lsof -i[46] [protocol][@hostname|hostaddr][:service|port]
	46：IPv4或IPv6
	protocol：TCP or UDP
	hostname：Internet host name
	hostaddr：IPv4地址
	service：/etc/service中的服务名称(可以不只一个)
	port：端口号 (可以不只一个)

例如： 查看22端口现在运行的情况
[root@www ~]# lsof -i :22
COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
sshd     1390 root    3u  IPv4  13050      0t0  TCP *:ssh (LISTEN)
sshd     1390 root    4u  IPv6  13056      0t0  TCP *:ssh (LISTEN)
sshd    36454 root    3r  IPv4  94352      0t0  TCP www.magedu.com:ssh->172.16.0.1:50018 (ESTABLISHED)


上述命令中，每行显示一个打开的文件，若不指定条件默认将显示所有进程打开的所有文件。lsof输出各列信息的意义如下：
	COMMAND：进程的名称
	PID：进程标识符
	USER：进程所有者
	FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等
	TYPE：文件类型，如DIR、REG等
	DEVICE：指定磁盘的名称
	SIZE：文件的大小
	NODE：索引节点（文件在磁盘上的标识）
	NAME：打开文件的确切名称















国内著名电商某服务器的内核优化参数：

# Controls the default maxmimum size of a mesage queue
kernel.msgmnb = 65536

# Controls the maximum size of a message, in bytes
kernel.msgmax = 65536

# Controls the maximum shared segment size, in bytes
kernel.shmmax = 68719476736

# Controls the maximum number of shared memory segments, in pages
kernel.shmall = 4294967296
net.core.somaxconn = 32768
net.core.wmem_default = 8388608
net.core.rmem_default = 8388608
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_timestamps = 0
net.ipv4.tcp_synack_retries = 1
net.ipv4.tcp_syn_retries = 0
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_mem = 94500000 915000000 927000000
net.ipv4.tcp_max_orphans = 3276800
net.ipv4.ip_local_port_range = 1024  65535
net.ipv4.tcp_fin_timeout = 10
net.ipv4.tcp_keepalive_time = 100
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 8192
net.ipv4.tcp_max_tw_buckets = 20000








开启动OS时，向内核传递参数，隔离专用的物理核心；
中断处理：将隔离出的CPU从中断处理中脱离出来；
绑定进程至CPU上；



PC Server:
	CPU, Memory


NUMA： 
	numad
	numactl
	numastat

CPU及进程的优化思路：
CPU亲缘性
	taskset
	cpuset
	numa

内核参数：isolcpus=
把中断处理从隔离出来的CPU上剥离掉；
使用taskset绑定进程至其专用CPU；


磁盘io活动情况的查看：
	iostat
		-x
	dstat
		-r, -d


systemtap: 
	相关文档地址：http://www.redhat.com/docs/




SystemTap, OProfile, Valgrind, Perf



