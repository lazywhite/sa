# elasticsearch + logstash + kibana
最后，elasticsearch团队提供了对运行大集群的几点优化建议：

1.设置ES_HEAP_SIZE环境变量，保证JVM使用的最大和最小内存用量相同。如果设置的最小和最大内存不一样，这意味着当jvm需要额外的内存时（最多达到最大内存的大小），它会阻塞java进程来分配内存给它。结合使用旧版本的java情况就可以解释为什么集群中的节点会停顿、出现高负载和不断的进行内存分配的情况。elasticsearch团队建议给es设置50%的系统内存
2.缩短recover_after_time超时配置，这样恢复可以马上进行，而不是还要再等一段时间。
3.配置minimum_master_nodes，避免多个节点长期暂停时，有些节点的子集合试图自行组织集群，从而导致整个集群不稳定。
4.在es初始恢复的时候，一些节点用完了磁盘空间。这个不知道是怎样发生的，因为整个集群只使用了总空间的67%，不过相信这是由于之前的高负载和旧java版本引起的。elasticsearch的团队也在跟进这个问题。

-----------------------
ES node type
1. data node
# only store index
http.enabled=false(they will use transport module to communicate with each other)
node.master=false
node.data=true
2. dedicated master node (at least 3 node)
# do not process any request just ensure the instability of cluster
node.master=true
node.data=false
3. client node
# only gather data
node.master=false
node.data=false

---------------------
由于集群并未开启allocate， 导致重启数据节点后，全部变为unassigned shards
集群健康状态为黄色，并不会停止录入数据
curl localhost:9200/_cluster/settings

# v0.90.x and earlier
curl -XPUT 'localhost:9200/_settings' -d '{
    "index.routing.allocation.disable_allocation": false
}'

# v1.0+
curl -XPUT 'localhost:9200/_cluster/settings' -d '{
    "transient" : {
        "cluster.routing.allocation.enable" : "all"
    }
}'
---------------------
curl http://localhost:9200/_cat/recovery?v
curl localhost:9200/_cat/shards
curl  'http://localhost:9200/_recovery?pretty&human'

