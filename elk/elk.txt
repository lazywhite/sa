最后，elasticsearch团队提供了对运行大集群的几点优化建议：

1.设置ES_HEAP_SIZE环境变量，保证JVM使用的最大和最小内存用量相同。如果设置的最小和最大内存不一样，这意味着当jvm需要额外的内存时（最多达到最大内存的大小），它会阻塞java进程来分配内存给它。结合使用旧版本的java情况就可以解释为什么集群中的节点会停顿、出现高负载和不断的进行内存分配的情况。elasticsearch团队建议给es设置50%的系统内存

2.缩短recover_after_time超时配置，这样恢复可以马上进行，而不是还要再等一段时间。

3.配置minimum_master_nodes，避免多个节点长期暂停时，有些节点的子集合试图自行组织集群，从而导致整个集群不稳定。

4.在es初始恢复的时候，一些节点用完了磁盘空间。这个不知道是怎样发生的，因为整个集群只使用了总空间的67%，不过相信这是由于之前的高负载和旧java版本引起的。elasticsearch的团队也在跟进这个问题。

-----------------------
ES node type
1. data node
# only store index
http.enabled=false(they will use transport module to communicate with each
other
node.master=false
node.data=true
2. dedicated master node (at least 3 node)
# do not process any request just ensure the instability of cluster
node.master=true
node.data=false
3. client node
# only gather data
node.master=false
node.data=false
