db.testtable.find({age : {$lt :24, $gt : 17}})
>db.mycol.find({},{"title":1,_id:0}).limit(2)
>db.mycol.find({},{"title":1,_id:0}).limit(1).skip(1)
======================
固定集合属性及用法
属性

属性1:对固定集合进行插入速度极快
属性2:按照插入顺序的查询输出速度极快
属性3:能够在插入最新数据时,淘汰最早的数据
用法

用法1:储存日志信息
用法2:缓存一些少量的文档

创建固定集合
我们通过createCollection来创建一个固定集合，且capped选项设置为true：

>db.createCollection("cappedLogCollection",{capped:true,size:10000})
还可以指定文档个数,加上max:1000属性：

>db.createCollection("cappedLogCollection",{capped:true,size:10000,max:1000})
判断集合是否为固定集合:

>db.cappedLogCollection.isCapped()
如果需要将已存在的集合转换为固定集合可以使用以下命令：

>db.runCommand({"convertToCapped":"posts",size:10000})


固定集合查询
固定集合文档按照插入顺序储存的,默认情况下查询就是按照插入顺序返回的,也可以使用$natural调整返回顺序。

>db.cappedLogCollection.find().sort({$natural:-1})
固定集合的功能特点
可以插入及更新,但更新不能超出collection的大小,否则更新失败,不允许删除,但是可以调用drop()删除集合中的所有行,但是drop后需要显式地重建集合。

在32位机子上一个cappped
collection的最大值约为482.5M,64位上只受系统文件大小的限制。
=========================
mongofiles -d gridfs put song.mp3
>db.fs.files.find()




mongorestore --host 192.168.0.23:25017 outfile  (directory could be
database or collection)
mongodump --host 127.0.0.1:27017 -d chanjian_dev [-c collection] -o outfile



In MongoDB when you go to a sharded system and you don't see any balancing it could one of several things.

You may not have enough data to trigger balancing. That was definitely not your situation but some people may not realize that with default chunk size of 64MB it might take a while of inserting data before there is enough to split and balance some of it to other chunks.
The balancer may not have been running - since your other collections were getting balanced that was unlikely in your case unless this collection was sharded last after the balancer was stopped for some reason.
The chunks in your collection can't be moved. This can happen when the shard key is not granular enough to split the data into small enough chunks. As it turns out this was your case because your shard key turned out not to be granular enough for this large a collection - you have 105 chunks (which probably corresponds to the number of unique job_id values) and over 30GB of data. When the chunks are too large and the balancer can't move them it tags them as "jumbo" (so it won't spin its wheels trying to migrate them).
How to recover from a poor choice of a shard key? Normally it's very painful to change the shard key - since shard key is immutable you have to do an equivalent of a full data migration to get it into a collection with another shard key. However, in your case the collection is all on one shard still, so it should be relatively easy to "unshard" the collection and reshard it with a new shard key. Because the number of job_ids is relatively small I would recommend using a regular index to shard on job_id,customer_code since you probably query on that and I'm guessing it's always set at document creation time.
